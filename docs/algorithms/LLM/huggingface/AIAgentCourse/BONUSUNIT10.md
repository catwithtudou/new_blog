# Bonus Unit 1. Fine-tuning an LLM for Function-calling

## Function-calling 简介

**1. 什么是 Function-calling ？**

函数调用(Function Calling)是一种使大型语言模型(LLM)能够与环境交互的技术，最初由GPT-4引入，后被其他模型采纳。与传统智能体工具不同，函数调用能力是模型**通过训练习得的**，而非仅依赖提示工程。

函数调用的核心特点：

- 允许模型主动执行环境操作
- 通过微调而非提示获得能力
- 减少对复杂提示工程的依赖

**2. 函数调用的工作流程**

函数调用遵循"思考-行动-观察"的循环：

| 阶段 | 说明 |
|------|------|
| **思考** | 模型分析需要采取哪些行动来实现目标 |
| **行动** | 以正确格式调用函数并停止生成 |
| **观察** | 接收函数执行结果并继续思考 |

**3. 对话角色的扩展**

函数调用为标准对话流程引入了新角色：

```
传统对话角色：
- user（用户）
- assistant（助手）

函数调用新增角色：
- function_call（行动）
- tool（观察）
```

示例对话结构：
```json
[
  {"role": "user", "content": "我的交易T1001状态如何？"},
  {
    "role": "assistant",
    "content": "",
    "function_call": {
      "name": "retrieve_payment_status",
      "arguments": "{\"transaction_id\": \"T1001\"}"
    }
  },
  {
    "role": "tool",
    "name": "retrieve_payment_status",
    "content": "{\"status\": \"已支付\"}"
  },
  {
    "role": "assistant",
    "content": "您的交易T1001已成功支付。"
  }
]
```

**4. 特殊标记(Special Tokens)**

为支持函数调用，模型需要理解特定的标记：

| 特殊标记 | 用途 |
|---------|------|
| `[AVAILABLE_TOOLS]` | 标记可用工具列表开始 |
| `[/AVAILABLE_TOOLS]` | 标记可用工具列表结束 |
| `[TOOL_CALLS]` | 标记工具调用开始（执行"行动"） |
| `[TOOL_RESULTS]` | 标记工具调用结果（"观察"） |
| `[/TOOL_RESULTS]` | 标记观察结束（模型可继续生成） |

## Fine-tuning 过程

**1. 模型训练的三步骤**

模型训练通常分为三个阶段：

1. **预训练**：模型在大量数据上学习基础语言能力，产出如`google/gemma-2-2b`的基础模型
2. **微调**：模型学习遵循指令，可由模型创建者或社区完成，如`google/gemma-2-2b-it`
3. **对齐**：模型适应特定偏好，如客服机器人永不对客户无礼

在本教程中，我们基于已经过指令微调的`google/gemma-2-2b-it`构建函数调用模型，这可以减少模型需要学习的信息量。

**2. LoRA 微调技术**

LoRA（低秩适应）是一种轻量级训练技术，显著减少可训练参数数量：

| LoRA特点 | 描述 |
|---------|------|
| **工作原理** | 在模型中插入少量新权重作为适配器 |
| **训练效率** | 更快、更节省内存、产生更小的权重文件 |
| **技术细节** | 向Transformer层添加秩分解矩阵对，同时"冻结"模型其他部分 |
| **推理优势** | 可将适配器权重与基础模型合并，无额外延迟 |

LoRA 特别适合以有限资源将大型语言模型适应特定任务或领域，显著降低训练所需内存。

**3. 微调数据集准备**

为函数调用微调模型需要特殊格式的数据集，包含以下元素：

- 用户查询
- 模型的思考过程
- 函数调用（包括函数名和参数）
- 函数执行结果
- 最终回复

每个训练样本应包含完整的交互循环，从用户查询到最终回复。

**4. 微调过程**

微调过程的关键步骤：

1. **准备基础模型**：加载预训练模型（如`google/gemma-2-2b-it`）
2. **添加特殊标记**：为模型添加函数调用相关的特殊标记
3. **准备LoRA配置**：设置适配器结构和训练参数
4. **数据处理**：将训练数据转换为模型可理解的格式
5. **训练执行**：使用`SFTTrainer`进行监督微调
6. **模型推送**：将微调后的模型上传至 Hugging Face Hub

```python
# 示例代码：添加特殊标记
from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("google/gemma-2-2b-it")
# 添加函数调用所需的特殊标记
tokenizer.add_special_tokens({
    "additional_special_tokens": [
        "[AVAILABLE_TOOLS]",
        "[/AVAILABLE_TOOLS]",
        "[TOOL_CALLS]",
        "[TOOL_RESULTS]",
        "[/TOOL_RESULTS]"
    ]
})
```

## 函数调用模型评估与应用

**1. 模型评估**

评估微调后的函数调用模型应关注以下方面：

- **函数选择准确性**：模型是否正确选择适合任务的函数
- **参数传递准确性**：模型是否提供正确参数格式
- **结果解释能力**：模型是否正确理解并解释函数执行结果
- **多轮对话能力**：模型是否能维持多轮函数调用交互

**2. 实际应用场景**

函数调用模型适用于多种场景：

| 应用场景 | 描述 |
|---------|------|
| **个人助手** | 执行日程安排、提醒设置、信息检索 |
| **客户服务** | 查询订单状态、处理退款请求、解答产品问题 |
| **智能家居** | 控制智能设备、调整环境设置、创建自动化流程 |
| **数据分析** | 执行数据查询、生成报表、执行简单分析 |

**3. 模型限制**

函数调用模型仍存在一些限制：

- **依赖预定义函数**：仅能使用明确定义的功能
- **工具使用能力**：虽经过训练，但可能仍有错误或不一致
- **复杂推理**：复杂场景下可能需要多个函数调用才能完成任务

## 总结

为函数调用微调大型语言模型是一项强大技术，使模型能够有效地与外部工具交互。通过LoRA等轻量级训练技术，您可以高效地为模型添加函数调用能力，而无需昂贵的完整模型重训练。

关键收获：

1. **函数调用原理**：理解"思考-行动-观察"循环及特殊标记的作用
2. **LoRA 技术**：掌握轻量级、高效的模型适应方法
3. **微调流程**：学习从数据准备到模型部署的完整过程
4. **应用扩展**：能够将函数调用模型应用于各种实际场景

通过本单元学习，您已具备为不同模型添加函数调用能力的知识和技能，能够创建更具交互性和实用性的AI智能体。